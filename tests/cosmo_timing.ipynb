{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#info_theory = {\"camb\": {\"extra_args\": {\"lens_potential_accuracy\": 1}}}\n",
    "info_theory = {\"classy\": {\"extra_args\": {\"non linear\": \"halofit\"}}}\n",
    "\n",
    "modules = \"/home/jesus/scratch/modules/\"\n",
    "\n",
    "n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prior] *WARNING* External prior 'SZ' loaded. Mind that it might not be normalized!\n",
      "[planck_2015_lowl] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_lowTEB] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_plikHM_TT] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_plikHM_TTTEEE] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_plikHM_TT_unbinned] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_plikHM_TTTEEE_unbinned] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_lensing] Importing clik from /home/jesus/scratch/modules/code/planck_2015\n",
      "[planck_2015_lensing_cmblikes] Reading data from /home/jesus/scratch/modules/data/planck_supp_data_and_covmats/lensing/smica_g30_ftl_full_pp.dataset\n",
      "[bicep_keck_2014] Reading data from /home/jesus/scratch/modules/data/bicep_keck_2014/BK14_cosmomc/data/BK14/BK14_dust.dataset\n",
      "[sn_jla] Reading data from /home/jesus/scratch/modules/data/sn_data/JLA/jla.dataset\n",
      "[sn_jla_lite] Reading data from /home/jesus/scratch/modules/data/sn_data/JLA/jla.dataset\n",
      "[sn_pantheon] Reading data from /home/jesus/scratch/modules/data/sn_data/Pantheon/full_long.dataset\n",
      "[classy] Importing *local* classy from /home/jesus/scratch/modules/code/classy\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n",
      "[classy] *WARNING* Requesting BB for ell>50 or lensing Cl's: using Halofit is recommended (and you are not using it). To activate it, set 'non_linear: halofit' in classy's 'extra_args'.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "from cobaya.conventions import _likelihood, _theory, _timing, _path_install\n",
    "from cobaya.tools import recursive_update\n",
    "from cobaya.cosmo_input import create_input, planck_base_model\n",
    "from cobaya.model import get_model\n",
    "\n",
    "from test_cosmo_planck_2015 import params_lowTEB_highTTTEEE\n",
    "\n",
    "info = create_input(planck_names=True, theory=list(info_theory)[0], **planck_base_model)\n",
    "info = recursive_update(info, {_theory: info_theory})\n",
    "\n",
    "likelihoods = [\n",
    "    \"planck_2015_lowl\", \"planck_2015_lowTEB\",\n",
    "    \"planck_2015_plikHM_TT\", \"planck_2015_plikHM_TTTEEE\",\n",
    "    \"planck_2015_plikHM_TT_unbinned\", \"planck_2015_plikHM_TTTEEE_unbinned\",\n",
    "    \"planck_2015_lensing\", \"planck_2015_lensing_cmblikes\",\n",
    "    \"bicep_keck_2014\",\n",
    "    \"H0_riess2018a\", \"H0_riess2018b\",\n",
    "    \"sdss_dr12_consensus_bao\", \"sdss_dr12_consensus_full_shape\", \"sdss_dr12_consensus_final\",\n",
    "    \"sdss_dr7_mgs\", \"sixdf_2011_bao\",\n",
    "    \"sn_jla\", \"sn_jla_lite\", \"sn_pantheon\"    \n",
    "]\n",
    "\n",
    "# NB: It's possible that DES makes everything else slower, since it adds many more\n",
    "# redshifts to the computation, so there are many more redshifts to select the\n",
    "# required e.g. H(z) from, making e.g. SN and BAO likes slower (longer theory code request)\n",
    "\n",
    "info[_likelihood] = odict([[l,None] for l in likelihoods])\n",
    "\n",
    "# No fsigma8 in classy!\n",
    "if list(info_theory)[0] == \"classy\":\n",
    "    info[_likelihood].pop(\"sdss_dr12_consensus_final\")\n",
    "    info[_likelihood].pop(\"sdss_dr12_consensus_full_shape\")\n",
    "\n",
    "info[_timing] = True\n",
    "info[_path_install] = modules\n",
    "model = get_model(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_lowTEB_highTTTEEE.pop(\"H0\", None)\n",
    "\n",
    "for i in range(n):\n",
    "    point = dict(zip(model.parameterization.sampled_params(), model.prior.sample(ignore_external=True)[0]))\n",
    "    point.update(params_lowTEB_highTTTEEE)\n",
    "    model.loglike(point, cached=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           time    speed old speed    factor\n",
      "planck_2015_lowl                    0.000251658  3973.65      2900  0.729808\n",
      "planck_2015_lowTEB                     0.245518  4.07302         4  0.982072\n",
      "planck_2015_plikHM_TT                 0.0107683  92.8655        60  0.646096\n",
      "planck_2015_plikHM_TTTEEE             0.0380948  26.2503        25  0.952370\n",
      "planck_2015_plikHM_TT_unbinned          0.12392  8.06975        10  1.239196\n",
      "planck_2015_plikHM_TTTEEE_unbinned     0.587045  1.70345         2  1.174090\n",
      "planck_2015_lensing                   0.0012351   809.65       800  0.988081\n",
      "planck_2015_lensing_cmblikes        0.000916348  1091.29       700  0.641443\n",
      "bicep_keck_2014                       0.0109873  91.0144       100  1.098727\n",
      "H0_riess2018a                       0.000242432  4124.86      6500  1.575810\n",
      "H0_riess2018b                       0.000186495  5362.09      6500  1.212215\n",
      "sdss_dr12_consensus_bao             0.000636946  1569.99      2500  1.592365\n",
      "sdss_dr12_consensus_full_shape              NaN      NaN       NaN       NaN\n",
      "sdss_dr12_consensus_final                   NaN      NaN       NaN       NaN\n",
      "sdss_dr7_mgs                         0.00032378  3088.52      2500  0.809449\n",
      "sixdf_2011_bao                      0.000264884  3775.23      2500  0.662211\n",
      "sn_jla                                0.0695523  14.3777        15  1.043284\n",
      "sn_jla_lite                            0.162699  6.14633         4  0.650795\n",
      "sn_pantheon                           0.0096332  103.808       500  4.816602\n",
      "theory                                  5.17652  0.19318       0.2  1.035303\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(columns=[\"time\", \"speed\", \"old speed\"], index=likelihoods)\n",
    "for name in [_theory] + list(model.likelihood):\n",
    "    like = model.likelihood[name]\n",
    "    df.at[name, \"time\"] = like.time_avg\n",
    "    df.at[name, \"speed\"] = 1/like.time_avg\n",
    "    df.at[name, \"old speed\"] = like.speed\n",
    "    df.at[name, \"factor\"] = like.speed*like.time_avg\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           time     speed old speed    factor\n",
      "planck_2015_lowl                    0.000328891   3040.52      2900  0.953785\n",
      "planck_2015_lowTEB                     0.243641   4.10439         4  0.974565\n",
      "planck_2015_plikHM_TT                 0.0118594   84.3216        60  0.711561\n",
      "planck_2015_plikHM_TTTEEE              0.038316   26.0987        25  0.957901\n",
      "planck_2015_plikHM_TT_unbinned         0.123394   8.10415        10  1.233935\n",
      "planck_2015_plikHM_TTTEEE_unbinned     0.587823   1.70119         2  1.175646\n",
      "planck_2015_lensing                  0.00120521   829.733       800  0.964166\n",
      "planck_2015_lensing_cmblikes        0.000872457   1146.19       700  0.610720\n",
      "bicep_keck_2014                       0.0115133   86.8561       100  1.151330\n",
      "H0_riess2018a                       0.000269573   3709.57      6500  1.752223\n",
      "H0_riess2018b                       0.000215471      4641      6500  1.400560\n",
      "sdss_dr12_consensus_bao             0.000690948   1447.29      2500  1.727369\n",
      "sdss_dr12_consensus_full_shape      0.000635021   1574.75      2500  1.587552\n",
      "sdss_dr12_consensus_final            0.00060498   1652.95      2500  1.512450\n",
      "sdss_dr7_mgs                        0.000281832   3548.21      2500  0.704581\n",
      "sixdf_2011_bao                      0.000246782   4052.15      2500  0.616956\n",
      "sn_jla                                0.0631997   15.8229        15  0.947995\n",
      "sn_jla_lite                            0.163242   6.12587         4  0.652969\n",
      "sn_pantheon                          0.00944887   105.833       500  4.724436\n",
      "theory                                  3.28798  0.304138       0.4  1.315192\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(columns=[\"time\", \"speed\", \"old speed\"], index=likelihoods)\n",
    "for name in [_theory] + list(model.likelihood):\n",
    "    like = model.likelihood[name]\n",
    "    df.at[name, \"time\"] = like.time_avg\n",
    "    df.at[name, \"speed\"] = 1/like.time_avg\n",
    "    df.at[name, \"old speed\"] = like.speed\n",
    "    df.at[name, \"factor\"] = like.speed*like.time_avg\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
